<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Motion Synth</title>
  <style>
  body {
    background: black;
  }
  canvas, video { 
    position: fixed;
    top: 0; 
    left: 0;
    width: 100vw;
    height: 100vh;
  }
  video {
    object-fit: fill;
    pointer-events: none;
    -webkit-filter: blur(25px);
    transform: scaleX(-1);
    opacity: 0.25;
    z-index: 1;
  }
  </style>
</head>
<body>
<video width="320" height="240" id="video" muted></video>
<canvas id="visuals"></canvas>
<script>
"use strict";

/* TODO Document 
Create harmonic sounds by filtering white noise by resonances peaks corresponding to MIDI notes' corresponding fundamental frequencies, all connected to a master buss with a limiter, a gain control and a FFT analyser responsible for the visualizations.
*/

// Require browser functionality.
if (navigator.mediaDevices === undefined) alert("Please switch browser to the latest desktop version of Google Chrome.");
if (AudioContext === 'undefined') alert("Please make sure your browser supports Web Audio.");

// Scale canvas to viewport.
function scaleVisuals() {
  visuals.width = window.innerWidth;
  visuals.height = window.innerHeight;
}
window.onload = function() { scaleVisuals() };
window.onresize = function() { scaleVisuals() };


// Setup motion detection with a webcam to create and trigger sounds.
navigator.mediaDevices.getUserMedia({video: true}).then(function(stream) {
  video.src = window.URL.createObjectURL(stream);
  video.onloadedmetadata = function(e) { 
    console.log(e);
    video.play();
      
    // Motion detection parameters.
    var threshold = 0.25; // Percentage of changed pixels required in a motion detect region for the region to trigger a motion event.
    var rows = 10; // Amplitudes
    var columns = notes.length; // Pitches
    function onMotionDetected(e) {
      var noteId = e.x;
      var amplitude = 1 - (e.y / rows);
      notes[noteId].play(amplitude);
    }

    // Create canvas to blit video frames to.
    var c = document.createElement('canvas');
    c.width = video.width;
    c.height = video.height;
    var frames = c.getContext('2d');
    frames.translate(c.width, 0);
    frames.scale(-1, 1);
      
    // Perform motion detection to trigger notes, analyse and visualize audio continously.
    var ctx = visuals.getContext('2d');
    function loop() {
      
      // Blit video to canvas.
      frames.drawImage(video, 0, 0, video.width, video.height);
      var currentFrame = frames.getImageData(0, 0, video.width, video.height); 
      
      // Convert and playback video frame as audio.
      source.setImage(currentFrame);
              
      // Motion detect and trigger audio filters in callback.
      detectMotion(currentFrame, threshold, rows, columns, onMotionDetected);
      
      // Render graphics on top of video frame.
      visualize(ctx);
      
      // Call continuously.
      requestAnimationFrame(loop);
    }
    loop();
  };
}).catch(function(e) {
  console.error(e);
  alert("Motion detection not working (" + e.name + "). This website requires a webcam.");
});


// Setup audio context.
var ac = new AudioContext();

// Create master buss with gain controls, a limiter, and some EQ:ing.
var masterBuss = function(audioContext) {  

  // Gain 
  var masterIn = audioContext.createGain();
  var masterOut = audioContext.createGain();
  masterIn.gain.value = 0.9;
  masterOut.gain.value = 0.9;

  // Limiter
  var compressor = audioContext.createDynamicsCompressor();
  compressor.ratio.value = 20;
  compressor.threshold.value = -30;
  
  // EQ
  var filter = audioContext.createBiquadFilter();
  filter.type = 'highshelf';
  filter.frequency.value = 1000;
  filter.gain.value = -24;

  // Effects chain
  masterIn.connect(filter);
  filter.connect(compressor);
  compressor.connect(masterOut);
  masterOut.connect(audioContext.destination);
  
  return masterIn; // So that the chain can be prepended with audio units.
}(ac);

// Source audio is noise generated from the latest webcam frame, and looped continuously. A solid color will produce a flat audio wave, and myrornas krig will produce white noise.
var source = ac.createBufferSource();
source.buffer = ac.createBuffer(1, 307200/4, ac.sampleRate);
source.loop = true;
source.start(0);
var data = source.buffer.getChannelData(0);
for (var i = 0; i < data.length; ++i) data[i] = random(-1,1);
AudioBufferSourceNode.prototype.setImage = function(image) { 

  // Convert image data to audio buffer. 
  var data = source.buffer.getChannelData(0);

  for (var i = 0; i < data.length; ++i) {
    var pixel = i*4;
    
    var r = image.data[pixel];
    var g = image.data[pixel+1];
    var b = image.data[pixel+2];
    var a = image.data[pixel+3];
    
    var avg = (r+g+b+a)/4;
    
    data[i] = 2 * avg / 255 - 1
  }
  
  // Don't care about spatial data in image. Randomly reorder samples.
  //TODO Find intuitive coupling between spatial ordering in an image and the audio instead of shuffling.
  shuffle(data);
};

// Setup tessitura like a piano, but with only one scale.
var lowestNote = 21;
var highestNote = 107;
var scale = [0, 2, 4, 5, 7, 9, 11];
var notes = [];
for (var i = 0; i < (scale.length / 12) * (highestNote - lowestNote); ++i) {
  var octave = Math.floor(i / scale.length);
  var note = lowestNote + octave * 12 + scale[i % scale.length];
  var g = new Note(note, ac, source);
  notes.push(g);
}

// A note consists of several resonance peaks filtering the buffer source at the corresponding note frequency.
function Note(midiNote, audioContext, bufferSource) {
  this.resonances = [];
  this.note = midiNote;

  var peaks = 1; //TODO Make this a GUI option.
  for (var i = 1; i <= peaks; ++i) {

    // Determine attack and release time for resonance peak.
    var attack = 0.5 * i * random(0.9, 1.1); //TODO Make this a GUI option.
    var release = 10.0 / i * random(0.9, 1.1); //TODO Make this a GUI option.
  
    // Filter out the desired fundamental from the buffer source.
    var filter = audioContext.createBiquadFilter();
    filter.type = filter.BANDPASS;
    filter.frequency.value = i * mtof(this.note);
    filter.detune.value = random(-10, 10);
    filter.Q.setValueAtTime(0, audioContext.currentTime);

    // Automatically pan around the sound continuously.
    var panner = audioContext.createPanner()
    panner.panningModel = "equalpower";
    var w = (this.note - lowestNote) / (highestNote - lowestNote)
    var x = 2*w-1 * random(0.9, 1.1);
    var y = random(-w, w);
    var z = random(-w, w);
    panner.setPosition(x, y, z);
    setInterval(function () {
      x *= random(1-i/peaks, 1+i/peaks);
      y *= random(0.9, 1.1);
      z *= random(0.9, 1.1);
      panner.setPosition(x, y, z);
    }, 33);

    // Create volume control
    var volume = audioContext.createGain();
    volume.gain.setValueAtTime(0, audioContext.currentTime);

    // Connect components.
    volume.connect(masterBuss);
    panner.connect(volume);
    filter.connect(panner);
    bufferSource.connect(filter);
    
    this.resonances.push({
      filter: filter,
      panner: panner,
      volume: volume,
      attackTime: attack,
      releaseTime: release
    });
  }

  // Play sound from generator by an ADSR envelope.
  this.play = function(velocity) {
    var now = audioContext.currentTime;
    for (var i = 0; i < this.resonances.length; ++i) {
      var r = this.resonances[i];

      var peakWidth = Math.min(1000, velocity * 1000);
      var amplitude = Math.min(1, velocity / (i+1)); // Reduce amplitude for higher partials.
      
      r.filter.Q.cancelScheduledValues(now);
      r.filter.Q.setValueAtTime(r.filter.Q.value, now);
      r.filter.Q.linearRampToValueAtTime(peakWidth, now + r.attackTime);
      r.filter.Q.linearRampToValueAtTime(0, now + r.attackTime + r.releaseTime);
      
      r.volume.gain.cancelScheduledValues(now);
      r.volume.gain.setValueAtTime(r.volume.gain.value, now);
      r.volume.gain.linearRampToValueAtTime(amplitude, now + r.attackTime);
      r.volume.gain.linearRampToValueAtTime(0, now + r.attackTime + r.releaseTime);
    }
  };
}

// Visualize sound on canvas.
function visualize(ctx) {

  // Clear background (with ghosting).
  ctx.globalCompositeOperation = 'source-over';
  ctx.shadowBlur = 0;
  ctx.fillStyle = 'rgba(0,0,0,0.1)';
  ctx.fillRect(0, 0, ctx.canvas.width, ctx.canvas.height);
  
  // Draw stars
  ctx.globalCompositeOperation = 'screen';
  var w = ctx.canvas.width / notes.length;
  var h = ctx.canvas.height;
  for (var i = 0; i < notes.length; ++i) {
    for (var j = 0; j < notes[i].resonances.length; ++j) {
      var v = notes[i].resonances[j].volume.gain.value;
      var f = Math.max(0, Math.min(1, (notes[i].resonances[j].filter.frequency.value - mtof(lowestNote)) / mtof(highestNote - lowestNote)));
      var n = (notes[i].note - lowestNote) / (highestNote - lowestNote);
      var x = i * w;
      var y = ctx.canvas.height - v * ctx.canvas.height;
      ctx.shadowBlur = w*v;
      ctx.shadowColor = ctx.fillStyle = 'hsl(' + 360*(1-f) + ', ' + 100*v + '%, ' + 100*n + '%)';
      ctx.fillCircle(w / 2 + random(x - w*n*v, x + w*n*v), random(y - w*n*v, y + w*n*v), w*(1-n)*v);
    }
  }
}

// Perform video motion detection by calculating the pixel difference between previous and current frame and looking for changed pixels over a grid.
var previousFrame = null;
function detectMotion(currentFrame, threshold, rows, columns, motionDetectedCallback) {

  //TODO Simplify array initialization.
  var activePixels = new Array(currentFrame.height);
  for (var y = 0; y < currentFrame.height; ++y) {
    activePixels[y] = new Array(currentFrame.width);
    for (var x = 0; x < currentFrame.width; ++x) activePixels[y][x] = false;
  }

  // Go through RGBA data and calculate pixel-per-pixel difference between current and previous frame.
	if (previousFrame == null) previousFrame = currentFrame;
  var n = 0;
  for (var i = 0; i < currentFrame.data.length / 4; ++i) {
		var avg1 = (currentFrame.data[4*i] + currentFrame.data[4*i+1] + currentFrame.data[4*i+2] + currentFrame.data[4*i+3]) / 4;
		var avg2 = (previousFrame.data[4*i] + previousFrame.data[4*i+1] + previousFrame.data[4*i+2] + previousFrame.data[4*i+3]) / 4;
    var x = i % currentFrame.width;
    var y = Math.floor(i / currentFrame.width);
    activePixels[y][x] = Math.abs(avg1 - avg2) > 25 ? true : false;
    if (activePixels[y][x]) ++n;
	}
	previousFrame = currentFrame;
  
  // If too many pixels changed: do nothing.
  if (n > threshold * currentFrame.data.length / 4) return;

  // Look for enough changed pixels in each image area.
  var w = Math.floor(currentFrame.width / columns);
  var h = Math.floor(currentFrame.height / rows);
  var changedPixelsNeeded = threshold*w*h;
	for (var i = 0; i < columns; ++i) {
    for (var j = 0; j < rows; ++j) {
    
      // Count active pixels per area.
      var c = 0;
      for (var y = j*h; y < (j+1)*h; ++y) {
        for (var x = i*w; x < (i+1)*w; ++x) {
          if (activePixels[y][x]) ++c;
        }
      }
      
      // If enough active pixels trigger motion detected event for area.
      if (c > changedPixelsNeeded) {
        var e = {x: i, y: j};
        motionDetectedCallback(e);
        break;
      }
    }
  }
}

// Convert 2D canvas coordinates to playing parameters.
function getPlayingParameters(x, y, w, h) {
  return {
    noteId: Math.floor(x / (w / notes.length)),
    velocity: (h - y) / h
  }
}

// Convert a MIDI note number to a frequency.
function mtof(n) {
  return Math.pow(2, (n - 69) / 12) * 440;
}

// Convert a frequency to a MIDI note number.
function ftom(f) {
  return Math.floor(12 * Math.log(f / 440) / Math.log(2) + 49)
}

// Get a random float between the input range.
function random(min, max) {
  return Math.random() * (max - min) + min
}

// Shuffle an array (Fisher-Yates method).
function shuffle(array) {
  var counter = array.length, temp, index;

  while (counter > 0) {
    index = Math.floor(Math.random() * counter);
    counter--;
    temp = array[counter];
    array[counter] = array[index];
    array[index] = temp;
  }

  return array;
}

// Draw filled circles (just like fillRect).
CanvasRenderingContext2D.prototype.fillCircle = function(x, y, r) {
  this.beginPath();
  this.arc(x, y, r, 0, 2*Math.PI);
  this.fill();
}
</script>
</body>
</html>
